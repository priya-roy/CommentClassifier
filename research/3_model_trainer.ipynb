{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os   \n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    tokenizer_name: str\n",
    "    text_column: str\n",
    "    label_column: bool\n",
    "    penalty: str\n",
    "    random_state: int\n",
    "    max_iter: int\n",
    "    class_weight: str\n",
    "    max_features: str\n",
    "    ngram_range: list\n",
    "    stop_words: str\n",
    "    min_df: int\n",
    "    max_df:float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CommentClassifier.constants import *\n",
    "from src.CommentClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config=self.config.model_trainer\n",
    "        params=self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "\n",
    "        model_trainer_config=ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            tokenizer_name = config.tokenizer_name,\n",
    "            text_column=config.text_column,\n",
    "            label_column=config.label_column,\n",
    "            penalty = params.penalty,\n",
    "            random_state = params.random_state,\n",
    "            max_iter = params.max_iter,\n",
    "            class_weight = params.class_weight,\n",
    "            max_features = params.max_features,\n",
    "            ngram_range= params.ngram_range,\n",
    "            stop_words = params.stop_words,\n",
    "            min_df = params.min_df,\n",
    "            max_df = params.max_df\n",
    "        )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strat model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import yaml\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config=config\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Load dataset from the transformed file.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(self.config.data_path, \"train.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Dataset Loaded: {df.shape} rows, {df.columns.tolist()} columns\")\n",
    "            return df\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset not found at {file_path}\")\n",
    "        \n",
    "    def preprocess_data(self, df):\n",
    "        df = df.dropna(subset=[\"comment\"])  # Drop missing comments\n",
    "        df[\"comment\"] = df[\"comment\"].astype(str)  # Convert all to strings\n",
    "        \n",
    "        X = df[self.config.text_column]\n",
    "        y = df[self.config.label_column]\n",
    "\n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = vectorizer.transform(X_test)\n",
    "        print(\"✅ Data Preprocessing Complete\")\n",
    "        return X_train_tfidf, X_test_tfidf, y_train, y_test, vectorizer\n",
    "    \n",
    "    def train_model(self, X_train_tfidf, y_train):\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        return model\n",
    "    \n",
    "    def save_model(self, model, vectorizer):\n",
    "        \"\"\"\n",
    "        Saves the trained model and the TF-IDF vectorizer.\n",
    "        \"\"\"\n",
    "         ## Save model\n",
    "        model_path = os.path.join(self.config.root_dir, \"trained_model\",\"model.pkl\")\n",
    "        ## Save tokenizer\n",
    "        vectorizer_path = os.path.join(self.config.root_dir,\"tokenizer\", \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "        joblib.dump(model, model_path)\n",
    "        joblib.dump(vectorizer, vectorizer_path)\n",
    "\n",
    "        print(f\"✅ Model saved at: {model_path}\")\n",
    "        print(f\"✅ TF-IDF Vectorizer saved at: {vectorizer_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: YAML Content Type: <class 'dict'>\n",
      "DEBUG: YAML Content: {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/priya-roy/unhealthy-comments-Dataset/raw/refs/heads/main/commentClassification.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_transformation': {'text_column': 'comment', 'label_column': 'healthy', 'stopwords': 'english', 'lowercase': True, 'remove_special_characters': True, 'remove_extra_spaces': True, 'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_ingestion/commentClassification', 'tokenizer_name': 'nltk'}, 'tfidf_vectorizer': {'max_features': 10000, 'ngram_range': [1, 2], 'stop_words': 'english', 'min_df': 2, 'max_df': 0.9}, 'model_trainer': {'root_dir': 'artifacts/model_trainer', 'data_path': 'artifacts/data_transformation/commentClassification', 'tokenizer_name': 'nltk', 'text_column': 'comment', 'label_column': 'healthy'}, 'model_evaluation': {'metrics': ['accuracy', 'precision', 'recall', 'f1_score'], 'validation_split': 0.2, 'cross_validation': True, 'cv_folds': 5, 'root_dir': 'artifacts/model_evaluation', 'data_path': 'artifacts/data_transformation/commentClassification', 'model_path': 'artifacts/model_trainer/trained_model', 'tokenizer_path': 'artifacts/model_trainer/tokenizer', 'metric_file_name': 'artifacts/model_evaluation/metrics.csv'}, 'output': {'model_save_path': 'models/trained_model.pkl', 'vectorizer_save_path': 'models/tfidf_vectorizer.pkl', 'evaluation_report_path': 'reports/evaluation_report.txt', 'log_file_path': 'logs/pipeline.log'}}\n",
      "[2025-02-24 12:31:50,500: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "DEBUG: YAML Content Type: <class 'dict'>\n",
      "DEBUG: YAML Content: {'TrainingArguments': {'solver': 'liblinear', 'penalty': 'l2', 'random_state': 42, 'max_iter': 200, 'class_weight': 'balanced', 'max_features': 10000, 'ngram_range': [1, 2], 'stop_words': 'english', 'min_df': 2, 'max_df': 0.9}}\n",
      "[2025-02-24 12:31:50,503: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-02-24 12:31:50,504: INFO: common: created directory at: artifacts]\n",
      "[2025-02-24 12:31:50,505: INFO: common: created directory at: artifacts/model_trainer]\n",
      "Dataset Loaded: (28402, 19) rows, ['_unit_id', '_trusted_judgments', 'comment', 'antagonize', 'antagonize:confidence', 'condescending', 'condescending:confidence', 'dismissive', 'dismissive:confidence', 'generalisation', 'generalisation:confidence', 'generalisation_unfair', 'generalisation_unfair:confidence', 'healthy', 'healthy:confidence', 'hostile', 'hostile:confidence', 'sarcastic', 'sarcastic:confidence'] columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pj/lh27tt7s3sd1zql9n09bxk4w0000gn/T/ipykernel_32427/2697522207.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"comment\"] = df[\"comment\"].astype(str)  # Convert all to strings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Preprocessing Complete\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/pj/lh27tt7s3sd1zql9n09bxk4w0000gn/T/ipykernel_32427/2517108783.py\", line 8, in <module>\n",
      "    model_trainer.save_model(model, vectorizer)\n",
      "  File \"/var/folders/pj/lh27tt7s3sd1zql9n09bxk4w0000gn/T/ipykernel_32427/2697522207.py\", line 47, in save_model\n",
      "    joblib.dump(model, model_path)\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/joblib/numpy_pickle.py\", line 552, in dump\n",
      "    with open(filename, 'wb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/model_trainer/trained_model/model.pkl'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 992, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 804, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"/Users/priyaroy/Documents/Projects/nlp-projects/CommentClassifier/venv/lib/python3.10/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_trainer_config = config.get_model_trainer_config()\n",
    "model_trainer = ModelTrainer(model_trainer_config)\n",
    "df = model_trainer.load_dataset()\n",
    "X_train, X_test, y_train, y_test, vectorizer = model_trainer.preprocess_data(df)\n",
    "\n",
    "model = model_trainer.train_model(X_train, y_train)\n",
    "model_trainer.save_model(model, vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
